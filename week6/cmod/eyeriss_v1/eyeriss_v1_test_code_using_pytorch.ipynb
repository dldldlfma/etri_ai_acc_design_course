{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(1,1,3)\n",
    "conv.bias.data[0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        conv.weight.data[0][0][i][j] = i+j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[0., 1., 2.],\n",
       "          [1., 2., 3.],\n",
       "          [2., 3., 4.]]]], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data=torch.Tensor(1,1,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(32):\n",
    "    for j in range(32):\n",
    "        in_data[0][0][i][j] = i+j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  ..., 29., 30., 31.],\n",
       "          [ 1.,  2.,  3.,  ..., 30., 31., 32.],\n",
       "          [ 2.,  3.,  4.,  ..., 31., 32., 33.],\n",
       "          ...,\n",
       "          [29., 30., 31.,  ..., 58., 59., 60.],\n",
       "          [30., 31., 32.,  ..., 59., 60., 61.],\n",
       "          [31., 32., 33.,  ..., 60., 61., 62.]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = conv(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  48.,   66.,   84.,  102.,  120.,  138.,  156.,  174.,  192.,  210.,\n",
       "          228.,  246.,  264.,  282.,  300.,  318.,  336.,  354.,  372.,  390.,\n",
       "          408.,  426.,  444.,  462.,  480.,  498.,  516.,  534.,  552.,  570.],\n",
       "        [  66.,   84.,  102.,  120.,  138.,  156.,  174.,  192.,  210.,  228.,\n",
       "          246.,  264.,  282.,  300.,  318.,  336.,  354.,  372.,  390.,  408.,\n",
       "          426.,  444.,  462.,  480.,  498.,  516.,  534.,  552.,  570.,  588.],\n",
       "        [  84.,  102.,  120.,  138.,  156.,  174.,  192.,  210.,  228.,  246.,\n",
       "          264.,  282.,  300.,  318.,  336.,  354.,  372.,  390.,  408.,  426.,\n",
       "          444.,  462.,  480.,  498.,  516.,  534.,  552.,  570.,  588.,  606.],\n",
       "        [ 102.,  120.,  138.,  156.,  174.,  192.,  210.,  228.,  246.,  264.,\n",
       "          282.,  300.,  318.,  336.,  354.,  372.,  390.,  408.,  426.,  444.,\n",
       "          462.,  480.,  498.,  516.,  534.,  552.,  570.,  588.,  606.,  624.],\n",
       "        [ 120.,  138.,  156.,  174.,  192.,  210.,  228.,  246.,  264.,  282.,\n",
       "          300.,  318.,  336.,  354.,  372.,  390.,  408.,  426.,  444.,  462.,\n",
       "          480.,  498.,  516.,  534.,  552.,  570.,  588.,  606.,  624.,  642.],\n",
       "        [ 138.,  156.,  174.,  192.,  210.,  228.,  246.,  264.,  282.,  300.,\n",
       "          318.,  336.,  354.,  372.,  390.,  408.,  426.,  444.,  462.,  480.,\n",
       "          498.,  516.,  534.,  552.,  570.,  588.,  606.,  624.,  642.,  660.],\n",
       "        [ 156.,  174.,  192.,  210.,  228.,  246.,  264.,  282.,  300.,  318.,\n",
       "          336.,  354.,  372.,  390.,  408.,  426.,  444.,  462.,  480.,  498.,\n",
       "          516.,  534.,  552.,  570.,  588.,  606.,  624.,  642.,  660.,  678.],\n",
       "        [ 174.,  192.,  210.,  228.,  246.,  264.,  282.,  300.,  318.,  336.,\n",
       "          354.,  372.,  390.,  408.,  426.,  444.,  462.,  480.,  498.,  516.,\n",
       "          534.,  552.,  570.,  588.,  606.,  624.,  642.,  660.,  678.,  696.],\n",
       "        [ 192.,  210.,  228.,  246.,  264.,  282.,  300.,  318.,  336.,  354.,\n",
       "          372.,  390.,  408.,  426.,  444.,  462.,  480.,  498.,  516.,  534.,\n",
       "          552.,  570.,  588.,  606.,  624.,  642.,  660.,  678.,  696.,  714.],\n",
       "        [ 210.,  228.,  246.,  264.,  282.,  300.,  318.,  336.,  354.,  372.,\n",
       "          390.,  408.,  426.,  444.,  462.,  480.,  498.,  516.,  534.,  552.,\n",
       "          570.,  588.,  606.,  624.,  642.,  660.,  678.,  696.,  714.,  732.],\n",
       "        [ 228.,  246.,  264.,  282.,  300.,  318.,  336.,  354.,  372.,  390.,\n",
       "          408.,  426.,  444.,  462.,  480.,  498.,  516.,  534.,  552.,  570.,\n",
       "          588.,  606.,  624.,  642.,  660.,  678.,  696.,  714.,  732.,  750.],\n",
       "        [ 246.,  264.,  282.,  300.,  318.,  336.,  354.,  372.,  390.,  408.,\n",
       "          426.,  444.,  462.,  480.,  498.,  516.,  534.,  552.,  570.,  588.,\n",
       "          606.,  624.,  642.,  660.,  678.,  696.,  714.,  732.,  750.,  768.],\n",
       "        [ 264.,  282.,  300.,  318.,  336.,  354.,  372.,  390.,  408.,  426.,\n",
       "          444.,  462.,  480.,  498.,  516.,  534.,  552.,  570.,  588.,  606.,\n",
       "          624.,  642.,  660.,  678.,  696.,  714.,  732.,  750.,  768.,  786.],\n",
       "        [ 282.,  300.,  318.,  336.,  354.,  372.,  390.,  408.,  426.,  444.,\n",
       "          462.,  480.,  498.,  516.,  534.,  552.,  570.,  588.,  606.,  624.,\n",
       "          642.,  660.,  678.,  696.,  714.,  732.,  750.,  768.,  786.,  804.],\n",
       "        [ 300.,  318.,  336.,  354.,  372.,  390.,  408.,  426.,  444.,  462.,\n",
       "          480.,  498.,  516.,  534.,  552.,  570.,  588.,  606.,  624.,  642.,\n",
       "          660.,  678.,  696.,  714.,  732.,  750.,  768.,  786.,  804.,  822.],\n",
       "        [ 318.,  336.,  354.,  372.,  390.,  408.,  426.,  444.,  462.,  480.,\n",
       "          498.,  516.,  534.,  552.,  570.,  588.,  606.,  624.,  642.,  660.,\n",
       "          678.,  696.,  714.,  732.,  750.,  768.,  786.,  804.,  822.,  840.],\n",
       "        [ 336.,  354.,  372.,  390.,  408.,  426.,  444.,  462.,  480.,  498.,\n",
       "          516.,  534.,  552.,  570.,  588.,  606.,  624.,  642.,  660.,  678.,\n",
       "          696.,  714.,  732.,  750.,  768.,  786.,  804.,  822.,  840.,  858.],\n",
       "        [ 354.,  372.,  390.,  408.,  426.,  444.,  462.,  480.,  498.,  516.,\n",
       "          534.,  552.,  570.,  588.,  606.,  624.,  642.,  660.,  678.,  696.,\n",
       "          714.,  732.,  750.,  768.,  786.,  804.,  822.,  840.,  858.,  876.],\n",
       "        [ 372.,  390.,  408.,  426.,  444.,  462.,  480.,  498.,  516.,  534.,\n",
       "          552.,  570.,  588.,  606.,  624.,  642.,  660.,  678.,  696.,  714.,\n",
       "          732.,  750.,  768.,  786.,  804.,  822.,  840.,  858.,  876.,  894.],\n",
       "        [ 390.,  408.,  426.,  444.,  462.,  480.,  498.,  516.,  534.,  552.,\n",
       "          570.,  588.,  606.,  624.,  642.,  660.,  678.,  696.,  714.,  732.,\n",
       "          750.,  768.,  786.,  804.,  822.,  840.,  858.,  876.,  894.,  912.],\n",
       "        [ 408.,  426.,  444.,  462.,  480.,  498.,  516.,  534.,  552.,  570.,\n",
       "          588.,  606.,  624.,  642.,  660.,  678.,  696.,  714.,  732.,  750.,\n",
       "          768.,  786.,  804.,  822.,  840.,  858.,  876.,  894.,  912.,  930.],\n",
       "        [ 426.,  444.,  462.,  480.,  498.,  516.,  534.,  552.,  570.,  588.,\n",
       "          606.,  624.,  642.,  660.,  678.,  696.,  714.,  732.,  750.,  768.,\n",
       "          786.,  804.,  822.,  840.,  858.,  876.,  894.,  912.,  930.,  948.],\n",
       "        [ 444.,  462.,  480.,  498.,  516.,  534.,  552.,  570.,  588.,  606.,\n",
       "          624.,  642.,  660.,  678.,  696.,  714.,  732.,  750.,  768.,  786.,\n",
       "          804.,  822.,  840.,  858.,  876.,  894.,  912.,  930.,  948.,  966.],\n",
       "        [ 462.,  480.,  498.,  516.,  534.,  552.,  570.,  588.,  606.,  624.,\n",
       "          642.,  660.,  678.,  696.,  714.,  732.,  750.,  768.,  786.,  804.,\n",
       "          822.,  840.,  858.,  876.,  894.,  912.,  930.,  948.,  966.,  984.],\n",
       "        [ 480.,  498.,  516.,  534.,  552.,  570.,  588.,  606.,  624.,  642.,\n",
       "          660.,  678.,  696.,  714.,  732.,  750.,  768.,  786.,  804.,  822.,\n",
       "          840.,  858.,  876.,  894.,  912.,  930.,  948.,  966.,  984., 1002.],\n",
       "        [ 498.,  516.,  534.,  552.,  570.,  588.,  606.,  624.,  642.,  660.,\n",
       "          678.,  696.,  714.,  732.,  750.,  768.,  786.,  804.,  822.,  840.,\n",
       "          858.,  876.,  894.,  912.,  930.,  948.,  966.,  984., 1002., 1020.],\n",
       "        [ 516.,  534.,  552.,  570.,  588.,  606.,  624.,  642.,  660.,  678.,\n",
       "          696.,  714.,  732.,  750.,  768.,  786.,  804.,  822.,  840.,  858.,\n",
       "          876.,  894.,  912.,  930.,  948.,  966.,  984., 1002., 1020., 1038.],\n",
       "        [ 534.,  552.,  570.,  588.,  606.,  624.,  642.,  660.,  678.,  696.,\n",
       "          714.,  732.,  750.,  768.,  786.,  804.,  822.,  840.,  858.,  876.,\n",
       "          894.,  912.,  930.,  948.,  966.,  984., 1002., 1020., 1038., 1056.],\n",
       "        [ 552.,  570.,  588.,  606.,  624.,  642.,  660.,  678.,  696.,  714.,\n",
       "          732.,  750.,  768.,  786.,  804.,  822.,  840.,  858.,  876.,  894.,\n",
       "          912.,  930.,  948.,  966.,  984., 1002., 1020., 1038., 1056., 1074.],\n",
       "        [ 570.,  588.,  606.,  624.,  642.,  660.,  678.,  696.,  714.,  732.,\n",
       "          750.,  768.,  786.,  804.,  822.,  840.,  858.,  876.,  894.,  912.,\n",
       "          930.,  948.,  966.,  984., 1002., 1020., 1038., 1056., 1074., 1092.]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
